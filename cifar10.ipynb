{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10 ",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/cifar10.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKr3J-iT7Qac",
        "outputId": "a82fc939-b27c-40c7-b990-23dfc3856d91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/cifar10.tar.gz\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/drive/MyDrive/cifar10.tar.gz or\n",
            "        /content/drive/MyDrive/cifar10.tar.gz.zip, and cannot find /content/drive/MyDrive/cifar10.tar.gz.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, time, json\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2"
      ],
      "metadata": {
        "id": "K7ydN2T-l_G4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Draws bounding boxes on image (numpy array)."
      ],
      "metadata": {
        "id": "oTH_UfT1j5FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes_on_image_array(image, boxes, color=[], thickness=5):\n",
        "\n",
        "    # draw_bounding_boxes_on_image(image, boxes, color, thickness)\n",
        "    boxes_shape = boxes.shape\n",
        "    if not boxes_shape:\n",
        "        return\n",
        "    if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
        "        raise ValueError('Input must be of size [N, 4]')\n",
        "    for i in range(boxes_shape[0]):\n",
        "        \n",
        "        image_width = image.shape[1]\n",
        "        image_height = image.shape[0]\n",
        "        cv2.rectangle(image, boxes[i, 1], boxes[i, 0], boxes[i, 3] ,  boxes[i, 2], color[i], thickness)\n",
        "  \n",
        "    return image"
      ],
      "metadata": {
        "id": "em19mVTej3DB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matplotlib config\n",
        "plt.rc('image', cmap='gray')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits_with_boxes(images, pred_bboxes, bboxes, iou, title, bboxes_normalized=False):\n",
        "\n",
        "    n = len(images)\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 4))\n",
        "    plt.title(title)\n",
        "    plt.yticks([])\n",
        "    plt.xticks([])\n",
        "  \n",
        "    for i in range(n):\n",
        "      ax = fig.add_subplot(1, 10, i+1)\n",
        "      bboxes_to_plot = []\n",
        "      if (len(pred_bboxes) > i):\n",
        "        bbox = pred_bboxes[i]\n",
        "        bbox = [bbox[0] * images[i].shape[1], bbox[1] * images[i].shape[0], bbox[2] * images[i].shape[1], bbox[3] * images[i].shape[0]]\n",
        "        bboxes_to_plot.append(bbox)\n",
        "    \n",
        "      if (len(bboxes) > i):\n",
        "        bbox = bboxes[i]\n",
        "        if bboxes_normalized == True:\n",
        "          bbox = [bbox[0] * images[i].shape[1],bbox[1] * images[i].shape[0], bbox[2] * images[i].shape[1], bbox[3] * images[i].shape[0] ]\n",
        "        bboxes_to_plot.append(bbox)\n",
        "\n",
        "      img_to_draw = draw_bounding_boxes_on_image_array(image=images[i], boxes=np.asarray(bboxes_to_plot), color=[(255,0,0), (0, 255, 0)])\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "    \n",
        "      plt.imshow(img_to_draw)\n",
        "\n",
        "      if len(iou) > i :\n",
        "        color = \"black\"\n",
        "        if (iou[i][0] < iou_threshold):\n",
        "          color = \"red\"\n",
        "        ax.text(0.2, -0.3, \"iou: %s\" %(iou[i][0]), color=color, transform=ax.transAxes)\n",
        "        "
      ],
      "metadata": {
        "id": "TUx4IUypi_p2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read_image_tfds_with_original_bbox:\n",
        "\n",
        "-This function reads image from data\n",
        "\n",
        "-It also denormalizes the bounding boxes (it undoes the bounding box normalization that is performed by the previous two helper functions.)"
      ],
      "metadata": {
        "id": "ckZQn2Q2cS8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image_tfds_with_original_bbox(data):\n",
        "    image = data[\"image\"]\n",
        "    bbox = data[\"bbox\"]\n",
        "\n",
        "    shape = tf.shape(image)\n",
        "    factor_x = tf.cast(shape[1], tf.float32) \n",
        "    factor_y = tf.cast(shape[0], tf.float32)\n",
        "\n",
        "    bbox_list = [bbox[1] * factor_x , \n",
        "                 bbox[0] * factor_y, \n",
        "                 bbox[3] * factor_x, \n",
        "                 bbox[2] * factor_y]\n",
        "    return image, bbox_list"
      ],
      "metadata": {
        "id": "xAZt4nvzcAzb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# converts a dataset into numpy arrays of images and boxes "
      ],
      "metadata": {
        "id": "aCWeJGbQSonB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_to_numpy_util(dataset, batch_size=0, N=0):\n",
        "\n",
        "\n",
        "    take_dataset = dataset.shuffle(1024)\n",
        "\n",
        "    if batch_size > 0:\n",
        "        take_dataset = take_dataset.batch(batch_size)\n",
        "  \n",
        "    if N > 0:\n",
        "        take_dataset = take_dataset.take(N)\n",
        "        \n",
        "  #Checks whether the current thread has eager execution enabled.\n",
        "    if tf.executing_eagerly():\n",
        "        ds_images, ds_bboxes = [], []\n",
        "        for images, bboxes in take_dataset:\n",
        "            ds_images.append(images.numpy())\n",
        "            ds_bboxes.append(bboxes.numpy())\n",
        "        \n",
        "    return (np.array(ds_images), np.array(ds_bboxes))"
      ],
      "metadata": {
        "id": "AIo_Ngl8SeYp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the training images and their bounding box labels"
      ],
      "metadata": {
        "id": "_5Ld8v2BbGUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_visualization_training_dataset():      \n",
        "    #\twith_info : bool, if True, tfds.load will return the tuple (tf.data.Dataset, tfds.core.DatasetInfo), the latter containing the info associated with the builder.\n",
        "    dataset, info = tfds.load(\"Pet_Breeds\", split=\"train\", with_info=True, data_dir=data_dir, download=False)\n",
        "    print(info)\n",
        "    visualization_training_dataset = dataset.map(read_image_tfds_with_original_bbox, \n",
        "                                                 num_parallel_calls=16)\n",
        "    \n",
        "    ds = tf.data.Dataset.from_tensor_slices(dict(data_dir)).\\\n",
        "        map(read_image_tfds_with_original_bbox ,num_parallel_calls=16).\\\n",
        "        batch(4)\n",
        "\n",
        "\n",
        "    return visualization_training_dataset\n",
        "\n",
        "visualization_training_dataset = get_visualization_training_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "ltxpopctaZtS",
        "outputId": "9e2afcdb-4ce1-433a-ba2b-00c1b275a1b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-beda9336fa60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvisualization_training_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvisualization_training_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_visualization_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-beda9336fa60>\u001b[0m in \u001b[0;36mget_visualization_training_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_visualization_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#   with_info : bool, if True, tfds.load will return the tuple (tf.data.Dataset, tfds.core.DatasetInfo), the latter containing the info associated with the builder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pet_Breeds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     visualization_training_dataset = dataset.map(read_image_tfds_with_original_bbox, \n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(visualization_training_images, visualization_training_bboxes) =dataset_to_numpy_util(visualization_training_dataset, N=10)\n",
        "display_digits_with_boxes(np.array(visualization_training_images), np.array([]), np.array(visualization_training_bboxes), np.array([]), \"training images and their bboxes\")"
      ],
      "metadata": {
        "id": "N56f-cJwM3mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "         data_dir,\n",
        "      \n",
        "         seed=123,\n",
        "         image_size=(240, 240),\n",
        "         batch_size=64)\n",
        "\n",
        "print(type(dataset))"
      ],
      "metadata": {
        "id": "ZdoQvop6ywMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02ffa6c-69a8-471f-90a7-e6cd9235dde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3881 files belonging to 23 classes.\n",
            "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "builder = tfds.builder('Pet_Breeds', data_dir='/content/ds_pet_breeds/Pet_Breeds')\n",
        "builder.download_and_prepare() # this can take a few minutes\n",
        "exit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XfEEe40quJB2",
        "outputId": "c6fafdc4-0d1a-4afc-8f89-27847ec852ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatasetNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c58c4ea37936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pet_Breeds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/ds_pet_breeds/Pet_Breeds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this can take a few minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, data_dir, **builder_init_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0;31m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mnot_found_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, data_dir, **builder_init_kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;31m# Try loading the code (if it exists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_abstract\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_abstract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pytype: disable=bad-return-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset pet__breeds not found. Available datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- downsampled_imagenet\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kitti\n\t- kmnist\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- qa4mre\n\t- qasc\n\t- quickdraw_bitmap\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- resisc45\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- starcraft_video\n\t- stl10\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- vgg_face2\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- xnli\n\t- xquad\n\t- xsum\n\t- yelp_polarity_reviews\n\t- yes_no\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BvCggVoGug8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}